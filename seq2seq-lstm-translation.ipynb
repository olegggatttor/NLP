{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!python -m spacy download en_core_web_md\n",
    "!python -m spacy download ru_core_news_md\n",
    "!pip install navec\n",
    "!pip install slovnet\n",
    "!wget https://storage.yandexcloud.net/natasha-navec/packs/navec_hudlit_v1_12B_500K_300d_100q.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from navec import Navec\n",
    "from slovnet.model.emb import NavecEmbedding\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "import os\n",
    "\n",
    "path = 'navec_hudlit_v1_12B_500K_300d_100q.tar'\n",
    "navec = Navec.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_map(f, xs):\n",
    "    result = []\n",
    "    for x in xs:\n",
    "        result.extend(f(x))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('rus.txt', sep='\\t', header=None)\n",
    "df.columns = ['eng', 'rus', 'meta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_lang(data, nlp_lang: tuple, additional_tags):\n",
    "    nlp, lang = nlp_lang\n",
    "    dataset = []\n",
    "    for sample in tqdm(data, desc=f'Processing {lang} data'):\n",
    "        dataset.append([x.lemma_.lower() for x in nlp(sample) if  (lang == 'rus' and x.lemma_.lower() in navec) or \\\n",
    "                                                                  (lang == 'eng' and x.lemma_ not in '.:;,-()?!')])\n",
    "    all_words = flat_map(lambda x: x, dataset)\n",
    "    all_words_set = set(all_words + ['<pad>', '<unk>'] + additional_tags)\n",
    "    idx2word = dict(enumerate(all_words_set))\n",
    "    word2idx = {v: k for k, v in idx2word.items()}\n",
    "    return dataset, word2idx, idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "en_nlp = spacy.load('en_core_web_md',  disable=['parser', 'ner', 'textcat'])\n",
    "ru_nlp = spacy.load('ru_core_news_md', disable=['parser', 'ner', 'textcat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing eng data: 100%|█████████████| 363386/363386 [11:07<00:00, 544.13it/s]\n",
      "Processing rus data: 100%|█████████████| 363386/363386 [19:52<00:00, 304.69it/s]\n"
     ]
    }
   ],
   "source": [
    "eng_dataset, eng_word2idx, eng_idx2word = prepare_lang(df.eng.values, nlp_lang=(en_nlp, 'eng'), additional_tags=['<EOS>', '<SOS>'])\n",
    "ru_dataset, ru_word2idx, ru_idx2word = prepare_lang(df.rus.values, nlp_lang=(ru_nlp, 'rus'), additional_tags=[])\n",
    "ru_word2idx = {word: navec.vocab[word] for word in ru_word2idx}\n",
    "ru_idx2word = {v: k for k, v in ru_word2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_dataset_encoded = []\n",
    "eng_dataset_encoded = []\n",
    "for ru_sample, eng_sample in zip(ru_dataset, eng_dataset):\n",
    "    ru_dataset_encoded.append([\n",
    "        ru_word2idx[word] for word in ru_sample\n",
    "    ])\n",
    "    \n",
    "    eng_dataset_encoded.append([\n",
    "        eng_word2idx[word] for word in ['<SOS>', *eng_sample, '<EOS>']\n",
    "    ])\n",
    "\n",
    "    \n",
    "ru_dataset_encoded, eng_dataset_encoded = \\\n",
    "    tuple(zip(*filter(lambda ru_en: len(ru_en[0]) and len(ru_en[1]), zip(ru_dataset_encoded, eng_dataset_encoded))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rus2Eng(nn.Module):\n",
    "    def __init__(self, out_vocab_size, eng_sos_idx, eng_eos_idx, eng_pad_idx, input_size=300, hidden_size=300, bidirectional_encoder=True):\n",
    "        super().__init__()\n",
    "        self.ru_embeds = NavecEmbedding(navec)\n",
    "        self.eng_embeds = nn.Embedding(out_vocab_size, hidden_size)\n",
    "        self.ru_embeds.requires_grad = False\n",
    "        self.encoder = nn.LSTM(input_size, hidden_size, batch_first=False, bidirectional=bidirectional_encoder)\n",
    "        self.decoder = nn.LSTM(hidden_size, hidden_size, batch_first=False)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size // 2, bias=True),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_size // 2, out_vocab_size, bias=True)\n",
    "        )\n",
    "        self.eng_sos_idx = eng_sos_idx\n",
    "        self.eng_eos_idx = eng_eos_idx\n",
    "        self.eng_pad_idx = eng_pad_idx\n",
    "        self.bidirectional_encoder = bidirectional_encoder\n",
    "    \n",
    "    def ru_embed(self, x):\n",
    "        return self.ru_embeds(x)\n",
    "    \n",
    "    def eng_embed(self, x):\n",
    "        return self.eng_embeds(x)\n",
    "    \n",
    "    def forward(self, x, max_steps=-1): # single sentence mode\n",
    "        _, (h_n, c_n) = self.encoder(x)\n",
    "        if self.bidirectional_encoder:\n",
    "            h_n = h_n.mean(dim=0, keepdim=True)\n",
    "            c_n = c_n.mean(dim=0, keepdim=True)\n",
    "        token = self.eng_sos_idx\n",
    "        step = 0\n",
    "        result = []\n",
    "        while token != self.eng_eos_idx and (max_steps != -1 and step < max_steps):\n",
    "            print(eng_idx2word[token])\n",
    "            inp = torch.tensor([\n",
    "                [token]\n",
    "            ]).to(device)\n",
    "            inp = self.eng_embed(inp)\n",
    "            out, (h_n, c_n)  = self.decoder(inp, (h_n, c_n))\n",
    "            out = self.classifier(out)\n",
    "            token = out.argmax().item()\n",
    "            result.append(token)\n",
    "            step += 1\n",
    "        return result\n",
    "    \n",
    "    def train(self, inp, targets, criterion, use_teacher_forcing=False): # embeded input\n",
    "        seq_len = targets.shape[0]\n",
    "        out, (h_n, c_n) = self.encoder(inp)\n",
    "        outs = []\n",
    "        loss = 0\n",
    "        if self.bidirectional_encoder:\n",
    "            h_n = h_n.mean(dim=0, keepdim=True)\n",
    "            c_n = c_n.mean(dim=0, keepdim=True)\n",
    "        token = torch.full_like(self.eng_embed(targets[0:1]), self.eng_sos_idx)\n",
    "        for i in range(1, seq_len):\n",
    "            out, (h_n, c_n)  = self.decoder(token, (h_n, c_n))\n",
    "            distribution = self.classifier(out[0])\n",
    "            mask = targets[i] != self.eng_pad_idx\n",
    "            # print('=========================')\n",
    "            # print(list(map(lambda x: eng_idx2word[x.item()], distribution.argmax(dim=1))))\n",
    "            # print(list(map(lambda x: eng_idx2word[x.item()], targets[i])))\n",
    "            loss += criterion(distribution[mask], targets[i][mask])\n",
    "            token = self.eng_embed(targets[i:i+1]) if use_teacher_forcing else out\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ru2EngDataset(Dataset):\n",
    "    def __init__(self, ru, eng):\n",
    "        self.ru = list(map(torch.tensor, ru))\n",
    "        self.eng = list(map(torch.tensor, eng))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ru)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        return self.ru[idx], self.eng[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Ru2EngDataset(ru_dataset_encoded, eng_dataset_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_collate(batch):\n",
    "    (xx, yy) = zip(*batch)\n",
    "    x_lens = [len(x) for x in xx]\n",
    "    y_lens = [len(y) for y in yy]\n",
    "\n",
    "    xx_pad = pad_sequence(xx, batch_first=True, padding_value=ru_word2idx['<pad>']).transpose(1, 0)\n",
    "    yy_pad = pad_sequence(yy, batch_first=True, padding_value=eng_word2idx['<pad>']).transpose(1, 0)\n",
    "\n",
    "    return xx_pad, yy_pad, x_lens, y_lens\n",
    "\n",
    "data_loader = DataLoader(dataset=dataset, batch_size=32, shuffle=True, collate_fn=pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Rus2Eng(len(eng_word2idx), eng_word2idx['<SOS>'], eng_word2idx['<EOS>'], eng_word2idx['<pad>'], hidden_size=512).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-3)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=4)\n",
    "epochs = range(0, 41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_train(teacher_forcing=0.5):\n",
    "    for epoch in epochs:\n",
    "        bar = tqdm(data_loader)\n",
    "        i = 0\n",
    "        for ru_samp, eng_samp, ru_lens, eng_lens in bar:\n",
    "            optimizer.zero_grad()\n",
    "            ru_samp = ru_samp.to(device)\n",
    "            eng_samp = eng_samp.to(device)\n",
    "\n",
    "            ru_embeded = model.ru_embed(ru_samp)\n",
    "\n",
    "            ru_packed = pack_padded_sequence(ru_embeded, ru_lens, batch_first=False, enforce_sorted=False)\n",
    "\n",
    "            loss = model.train(ru_packed, eng_samp, criterion, use_teacher_forcing=np.random.uniform() < teacher_forcing)\n",
    "            if i % 100 == 0:\n",
    "                bar.set_description(f\"Epoch {epoch}: \" + str(loss.item()))\n",
    "            i += 1\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "        if epoch % 5 == 0:\n",
    "            torch.save(model.state_dict(), f'checkpoints/ru2en_{epoch}.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 23.091445922851562: 100%|████████| 11355/11355 [04:17<00:00, 44.06it/s]\n",
      "Epoch 1: 14.13554859161377: 100%|█████████| 11355/11355 [04:21<00:00, 43.48it/s]\n",
      "Epoch 2: 18.159461975097656: 100%|████████| 11355/11355 [04:22<00:00, 43.29it/s]\n",
      "Epoch 3: 9.35681438446045: 100%|██████████| 11355/11355 [04:20<00:00, 43.58it/s]\n",
      "Epoch 4: 31.027477264404297: 100%|████████| 11355/11355 [04:23<00:00, 43.10it/s]\n",
      "Epoch 5: 15.785499572753906: 100%|████████| 11355/11355 [04:21<00:00, 43.42it/s]\n",
      "Epoch 6: 14.352655410766602: 100%|████████| 11355/11355 [04:20<00:00, 43.57it/s]\n",
      "Epoch 7: 11.317116737365723: 100%|████████| 11355/11355 [04:23<00:00, 43.05it/s]\n",
      "Epoch 8: 64.5309066772461: 100%|██████████| 11355/11355 [04:20<00:00, 43.60it/s]\n",
      "Epoch 9: 26.826215744018555: 100%|████████| 11355/11355 [04:23<00:00, 43.10it/s]\n",
      "Epoch 10: 21.536630630493164: 100%|███████| 11355/11355 [04:10<00:00, 45.25it/s]\n",
      "Epoch 11: 7.5344977378845215: 100%|███████| 11355/11355 [04:07<00:00, 45.85it/s]\n",
      "Epoch 12: 15.145207405090332: 100%|███████| 11355/11355 [04:23<00:00, 43.16it/s]\n",
      "Epoch 13: 8.125508308410645: 100%|████████| 11355/11355 [04:16<00:00, 44.29it/s]\n",
      "Epoch 14: 6.854320526123047: 100%|████████| 11355/11355 [04:15<00:00, 44.42it/s]\n",
      "Epoch 15: 10.452266693115234: 100%|███████| 11355/11355 [04:17<00:00, 44.12it/s]\n",
      "Epoch 16: 19.16547203063965: 100%|████████| 11355/11355 [04:18<00:00, 43.95it/s]\n",
      "Epoch 17: 19.368431091308594: 100%|███████| 11355/11355 [04:17<00:00, 44.10it/s]\n",
      "Epoch 18: 15.247954368591309: 100%|███████| 11355/11355 [04:14<00:00, 44.70it/s]\n",
      "Epoch 19: 5.628897190093994: 100%|████████| 11355/11355 [04:14<00:00, 44.53it/s]\n",
      "Epoch 20: 6.322785377502441:   5%|▍         | 516/11355 [00:11<03:34, 50.49it/s]"
     ]
    }
   ],
   "source": [
    "mk_train(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('checkpoints/ru2en_40.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, gamma=0.9, step_size=4)\n",
    "epochs = range(41, 101)\n",
    "mk_train(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('checkpoints/ru2en_100.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 101: 15.205076217651367: 100%|██████| 11355/11355 [03:52<00:00, 48.78it/s]\n",
      "Epoch 102: 37.49637985229492: 100%|███████| 11355/11355 [03:43<00:00, 50.72it/s]\n",
      "Epoch 103: 15.313156127929688: 100%|██████| 11355/11355 [03:50<00:00, 49.35it/s]\n",
      "Epoch 104: 14.575763702392578: 100%|██████| 11355/11355 [03:50<00:00, 49.35it/s]\n",
      "Epoch 105: 10.401753425598145: 100%|██████| 11355/11355 [03:50<00:00, 49.20it/s]\n",
      "Epoch 106: 18.95008659362793: 100%|███████| 11355/11355 [03:47<00:00, 49.90it/s]\n",
      "Epoch 107: 19.970184326171875: 100%|██████| 11355/11355 [03:48<00:00, 49.74it/s]\n",
      "Epoch 108: 29.8555965423584: 100%|████████| 11355/11355 [03:45<00:00, 50.26it/s]\n",
      "Epoch 109: 19.25177574157715: 100%|███████| 11355/11355 [03:48<00:00, 49.73it/s]\n",
      "Epoch 110: 12.936820983886719: 100%|██████| 11355/11355 [03:46<00:00, 50.23it/s]\n",
      "Epoch 111: 20.40401268005371: 100%|███████| 11355/11355 [03:46<00:00, 50.17it/s]\n",
      "Epoch 112: 11.56313705444336: 100%|███████| 11355/11355 [03:53<00:00, 48.59it/s]\n",
      "Epoch 113: 11.230584144592285: 100%|██████| 11355/11355 [03:48<00:00, 49.67it/s]\n",
      "Epoch 114: 11.87619400024414: 100%|███████| 11355/11355 [03:49<00:00, 49.43it/s]\n",
      "Epoch 115: 15.653066635131836: 100%|██████| 11355/11355 [03:50<00:00, 49.29it/s]\n",
      "Epoch 116: 16.675626754760742: 100%|██████| 11355/11355 [03:48<00:00, 49.79it/s]\n",
      "Epoch 117: 20.75923728942871: 100%|███████| 11355/11355 [03:50<00:00, 49.36it/s]\n",
      "Epoch 118: 15.671333312988281: 100%|██████| 11355/11355 [03:49<00:00, 49.58it/s]\n",
      "Epoch 119: 9.168322563171387: 100%|███████| 11355/11355 [03:47<00:00, 49.94it/s]\n",
      "Epoch 120: 23.570344924926758: 100%|██████| 11355/11355 [03:49<00:00, 49.50it/s]\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, gamma=0.9, step_size=4)\n",
    "epochs = range(101, 121)\n",
    "mk_train(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('checkpoints/ru2en_120.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ru2en_translate(phrase):\n",
    "    with torch.no_grad():\n",
    "        lemmatized, _, _ = prepare_lang([phrase], nlp_lang=(ru_nlp, 'rus'), additional_tags=[])\n",
    "        ru_seq = torch.tensor([[ru_word2idx[word] for word in lemmatized[0]]])\n",
    "        ru_embeded_seq = model.ru_embed(ru_seq).transpose(1, 0)\n",
    "        ans = model(ru_embeded_seq, max_steps=100)\n",
    "        return \" \".join([eng_idx2word[x] for x in ans])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('checkpoints/ru2en_40.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rus data: 100%|███████████████████████| 1/1 [00:00<00:00, 347.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SOS>\n",
      "walk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'walk <EOS>'"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru2en_translate('идти')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rus data: 100%|███████████████████████| 1/1 [00:00<00:00, 273.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SOS>\n",
      "death\n",
      "\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'death \" <EOS>'"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru2en_translate('Смерть')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rus data: 100%|███████████████████████| 1/1 [00:00<00:00, 224.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SOS>\n",
      "you\n",
      "do\n",
      "not\n",
      "have\n",
      "to\n",
      "do\n",
      "it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'you do not have to do it <EOS>'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru2en_translate('Что ты делаешь?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
