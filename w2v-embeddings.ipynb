{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport nltk\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords, wordnet\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom tqdm import tqdm\nfrom sklearn.manifold import TSNE\nimport matplotlib.pyplot as plt\nimport re\n\nnltk.download('omw-1.4')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-21T14:18:46.325917Z","iopub.execute_input":"2022-12-21T14:18:46.326732Z","iopub.status.idle":"2022-12-21T14:18:49.670384Z","shell.execute_reply.started":"2022-12-21T14:18:46.326602Z","shell.execute_reply":"2022-12-21T14:18:49.669477Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"tweets_df = pd.read_csv('/kaggle/input/customer-support-on-twitter/twcs/twcs.csv')\nquerries = tweets_df.text.tolist()","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:18:49.672429Z","iopub.execute_input":"2022-12-21T14:18:49.673007Z","iopub.status.idle":"2022-12-21T14:19:04.077215Z","shell.execute_reply.started":"2022-12-21T14:18:49.672969Z","shell.execute_reply":"2022-12-21T14:19:04.076223Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def flat_map(f, xs):\n    result = []\n    for x in xs:\n        result.extend(f(x))\n    return result","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:19:04.078715Z","iopub.execute_input":"2022-12-21T14:19:04.079119Z","iopub.status.idle":"2022-12-21T14:19:04.087332Z","shell.execute_reply.started":"2022-12-21T14:19:04.079081Z","shell.execute_reply":"2022-12-21T14:19:04.086453Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def pos(nltk_tag):\n    if nltk_tag.startswith('J'):\n        return wordnet.ADJ\n    elif nltk_tag.startswith('V'):\n        return wordnet.VERB\n    elif nltk_tag.startswith('N'):\n        return wordnet.NOUN\n    elif nltk_tag.startswith('R'):\n        return wordnet.ADV\n    else:\n        return None","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:19:04.091120Z","iopub.execute_input":"2022-12-21T14:19:04.092004Z","iopub.status.idle":"2022-12-21T14:19:04.098759Z","shell.execute_reply.started":"2022-12-21T14:19:04.091949Z","shell.execute_reply":"2022-12-21T14:19:04.097782Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def lemmatize(token_tags):\n    result = []\n    for token, tag in token_tags:\n        pos_tag = pos(tag)\n        if pos_tag:\n            result.append(lemmatizer.lemmatize(token.lower(), pos_tag))\n    return result\n\ndef rm_stop_words(words):\n    return list(filter(lambda x: x is not None and not x.startswith(\"@\"), words))","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:19:04.100273Z","iopub.execute_input":"2022-12-21T14:19:04.100617Z","iopub.status.idle":"2022-12-21T14:19:04.119163Z","shell.execute_reply.started":"2022-12-21T14:19:04.100583Z","shell.execute_reply":"2022-12-21T14:19:04.113232Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"lemmatizer = WordNetLemmatizer()\ntokens = []\nfor text_part in tqdm(querries[:150000]):\n    tokens += list(map(rm_stop_words, \n                          map(lemmatize, \n                              map(lambda sentence: nltk.pos_tag(word_tokenize(sentence), lang='rus'), \n                                       sent_tokenize(text_part)))))","metadata":{"execution":{"iopub.status.busy":"2022-12-21T15:57:19.597193Z","iopub.execute_input":"2022-12-21T15:57:19.597566Z","iopub.status.idle":"2022-12-21T15:57:19.674681Z","shell.execute_reply.started":"2022-12-21T15:57:19.597533Z","shell.execute_reply":"2022-12-21T15:57:19.673145Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"  0%|          | 0/150000 [00:00<?, ?it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_24/207049833.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                           map(lemmatize, \n\u001b[1;32m      6\u001b[0m                               map(lambda sentence: nltk.pos_tag(word_tokenize(sentence), lang='rus'), \n\u001b[0;32m----> 7\u001b[0;31m                                        sent_tokenize(text_part)))))\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_24/207049833.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m      4\u001b[0m     tokens += list(map(rm_stop_words, \n\u001b[1;32m      5\u001b[0m                           map(lemmatize, \n\u001b[0;32m----> 6\u001b[0;31m                               map(lambda sentence: nltk.pos_tag(word_tokenize(sentence), lang='rus'), \n\u001b[0m\u001b[1;32m      7\u001b[0m                                        sent_tokenize(text_part)))))\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/nltk/tag/__init__.py\u001b[0m in \u001b[0;36mpos_tag\u001b[0;34m(tokens, tagset, lang)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \"\"\"\n\u001b[0;32m--> 165\u001b[0;31m     \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_tagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_pos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/nltk/tag/__init__.py\u001b[0m in \u001b[0;36m_get_tagger\u001b[0;34m(lang)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlang\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"rus\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPerceptronTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0map_russian_model_loc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"file:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRUS_PICKLE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0mtagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0map_russian_model_loc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger_ru\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger_ru')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_ru/averaged_perceptron_tagger_ru.pickle\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/opt/conda/nltk_data'\n    - '/opt/conda/share/nltk_data'\n    - '/opt/conda/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"],"ename":"LookupError","evalue":"\n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger_ru\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger_ru')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_ru/averaged_perceptron_tagger_ru.pickle\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/opt/conda/nltk_data'\n    - '/opt/conda/share/nltk_data'\n    - '/opt/conda/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n","output_type":"error"}]},{"cell_type":"code","source":"good_pattern = re.compile(\"[a-zA-Z0-9']+\", flags=re.UNICODE)","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:23:50.910437Z","iopub.execute_input":"2022-12-21T14:23:50.912054Z","iopub.status.idle":"2022-12-21T14:23:50.920217Z","shell.execute_reply.started":"2022-12-21T14:23:50.912017Z","shell.execute_reply":"2022-12-21T14:23:50.919292Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"filtered = list(filter(lambda x: len(x) > 1, tokens))","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:23:50.924310Z","iopub.execute_input":"2022-12-21T14:23:50.925676Z","iopub.status.idle":"2022-12-21T14:23:51.008271Z","shell.execute_reply.started":"2022-12-21T14:23:50.925642Z","shell.execute_reply":"2022-12-21T14:23:51.007426Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"tokens = list(map(lambda sent: list(filter(lambda word: \n                                      bool(good_pattern.fullmatch(word)), sent)), filtered))","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:23:51.009328Z","iopub.execute_input":"2022-12-21T14:23:51.009644Z","iopub.status.idle":"2022-12-21T14:23:52.492709Z","shell.execute_reply.started":"2022-12-21T14:23:51.009608Z","shell.execute_reply":"2022-12-21T14:23:52.491708Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"vocabulary_set = set(flat_map(lambda x: x, tokens))","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:23:52.497276Z","iopub.execute_input":"2022-12-21T14:23:52.497574Z","iopub.status.idle":"2022-12-21T14:23:52.677214Z","shell.execute_reply.started":"2022-12-21T14:23:52.497547Z","shell.execute_reply":"2022-12-21T14:23:52.676224Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"idx2word = dict(enumerate(vocabulary_set))\nword2idx = {v: k for k, v in idx2word.items()}","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:23:52.678787Z","iopub.execute_input":"2022-12-21T14:23:52.679193Z","iopub.status.idle":"2022-12-21T14:23:52.703178Z","shell.execute_reply.started":"2022-12-21T14:23:52.679156Z","shell.execute_reply":"2022-12-21T14:23:52.702213Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def skipgram_dataset(tokens, window_size=3):\n    dataset = []\n    for sentence in tokens:\n        encoded_sentence = list(map(lambda x: word2idx[x], sentence))\n        for token_pos, token in enumerate(encoded_sentence[window_size:-window_size], start=window_size):\n            context = encoded_sentence[token_pos - window_size:token_pos] + encoded_sentence[token_pos + 1:token_pos + window_size + 1]\n            dataset += [(torch.tensor(token), torch.tensor(ctx_token)) for ctx_token in context]\n    return dataset\n\ndef cbow_dataset(tokens, window_size=3):\n    dataset = []\n    for sentence in tokens:\n        encoded_sentence = list(map(lambda x: word2idx[x], sentence))\n        for token_pos, token in enumerate(encoded_sentence[window_size:-window_size], start=window_size):\n            context = encoded_sentence[token_pos - window_size:token_pos] + encoded_sentence[token_pos + 1:token_pos + window_size + 1]\n            dataset.append((torch.tensor(context), torch.tensor(token)))\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:23:52.704632Z","iopub.execute_input":"2022-12-21T14:23:52.705158Z","iopub.status.idle":"2022-12-21T14:23:52.716696Z","shell.execute_reply.started":"2022-12-21T14:23:52.705123Z","shell.execute_reply":"2022-12-21T14:23:52.715372Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class Word2VecModel(nn.Module):\n    def __init__(self, vocab_size, dim):\n            super().__init__()\n            self.encoder = nn.Embedding(vocab_size, dim)\n            weight_init_bound = 0.5 / dim\n            self.encoder.weight.data.uniform_(-weight_init_bound, weight_init_bound)\n            self.classifier = nn.Linear(dim, vocab_size)\n            self.vocab_size = vocab_size\n    \n    def forward(self, x):\n        raise Exception(\"unimplemented\")\n            \nclass SkipGramModel(Word2VecModel):\n    def forward(self, x):\n        return self.classifier(self.encoder(x))\n\nclass CBOWModel(Word2VecModel):\n    def forward(self, x):\n        encoded = self.encoder(x)\n        mean_context_vec = encoded.mean(dim=1)\n        return self.classifier(mean_context_vec)","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:23:52.718641Z","iopub.execute_input":"2022-12-21T14:23:52.719099Z","iopub.status.idle":"2022-12-21T14:23:52.728828Z","shell.execute_reply.started":"2022-12-21T14:23:52.719065Z","shell.execute_reply":"2022-12-21T14:23:52.727835Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def train(model, dataloader, criterion, optimizer, epochs):\n    for epoch in range(epochs):\n        epoch_loss, cnt = 0, 0\n        for x, y in tqdm(dataloader):\n            optimizer.zero_grad()\n            x, y = x.cuda(), y.cuda()\n            preds = model(x)\n            loss = criterion(preds, y)\n            epoch_loss += loss.item()\n            cnt += 1\n            loss.backward()\n            optimizer.step()\n        print(f\"Epoch {epoch}: mean_loss = {epoch_loss / cnt}\")\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:23:52.730322Z","iopub.execute_input":"2022-12-21T14:23:52.730724Z","iopub.status.idle":"2022-12-21T14:23:52.739493Z","shell.execute_reply.started":"2022-12-21T14:23:52.730662Z","shell.execute_reply":"2022-12-21T14:23:52.738610Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"loader = DataLoader(skipgram_dataset(tokens), batch_size=64, shuffle=True)\nw2v = SkipGramModel(len(vocabulary_set), 100).cuda()\noptimizer = optim.AdamW(w2v.parameters(), lr=5e-4)\ncriterion = nn.CrossEntropyLoss()\ntrained_skipgram = train(w2v, loader, criterion, optimizer, 10)","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:47:14.054996Z","iopub.execute_input":"2022-12-21T14:47:14.055359Z","iopub.status.idle":"2022-12-21T15:11:19.464484Z","shell.execute_reply.started":"2022-12-21T14:47:14.055328Z","shell.execute_reply":"2022-12-21T15:11:19.463469Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"100%|██████████| 44443/44443 [02:21<00:00, 313.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 0: mean_loss = 7.186765206213396\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 44443/44443 [02:22<00:00, 312.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: mean_loss = 6.905425988514417\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 44443/44443 [02:21<00:00, 313.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2: mean_loss = 6.813994961537243\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 44443/44443 [02:22<00:00, 312.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3: mean_loss = 6.754774928068816\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 44443/44443 [02:22<00:00, 312.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4: mean_loss = 6.718189181027896\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 44443/44443 [02:21<00:00, 313.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5: mean_loss = 6.694250118281022\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 44443/44443 [02:21<00:00, 313.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6: mean_loss = 6.677204001001628\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 44443/44443 [02:21<00:00, 313.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7: mean_loss = 6.664848562101593\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 44443/44443 [02:21<00:00, 313.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8: mean_loss = 6.655264619891174\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 44443/44443 [02:21<00:00, 313.35it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 9: mean_loss = 6.646360891428555\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"loader = DataLoader(cbow_dataset(tokens), batch_size=64, shuffle=True)\nw2v = CBOWModel(len(vocabulary_set), 100).cuda()\noptimizer = optim.AdamW(w2v.parameters(), lr=8e-4)\ncriterion = nn.CrossEntropyLoss()\ntrained_cbow = train(w2v, loader, criterion, optimizer, 15)","metadata":{"execution":{"iopub.status.busy":"2022-12-21T15:11:19.466563Z","iopub.execute_input":"2022-12-21T15:11:19.467189Z","iopub.status.idle":"2022-12-21T15:17:28.285443Z","shell.execute_reply.started":"2022-12-21T15:11:19.467151Z","shell.execute_reply":"2022-12-21T15:17:28.284465Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"100%|██████████| 7408/7408 [00:24<00:00, 305.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 0: mean_loss = 7.223738310275274\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7408/7408 [00:23<00:00, 308.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: mean_loss = 6.527001478180257\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7408/7408 [00:24<00:00, 307.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2: mean_loss = 6.20174361318028\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7408/7408 [00:24<00:00, 308.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3: mean_loss = 5.970465596177923\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7408/7408 [00:24<00:00, 307.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4: mean_loss = 5.78387161812566\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7408/7408 [00:23<00:00, 308.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5: mean_loss = 5.624774537706993\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7408/7408 [00:23<00:00, 308.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6: mean_loss = 5.485456250656243\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7408/7408 [00:24<00:00, 308.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7: mean_loss = 5.360456347594251\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7408/7408 [00:24<00:00, 307.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8: mean_loss = 5.249206174784551\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7408/7408 [00:24<00:00, 304.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9: mean_loss = 5.147958979718629\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7408/7408 [00:24<00:00, 308.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10: mean_loss = 5.056805751332711\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7408/7408 [00:24<00:00, 308.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11: mean_loss = 4.973473553233991\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7408/7408 [00:24<00:00, 306.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12: mean_loss = 4.89821871230077\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7408/7408 [00:24<00:00, 307.31it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13: mean_loss = 4.829506225546029\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7408/7408 [00:24<00:00, 308.41it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 14: mean_loss = 4.766646905413972\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"def negative_sampling(bag_of_words, n_negatives=10):\n    import random\n    from collections import Counter\n    frequencies = dict(Counter(map(lambda x: word2idx[x], bag_of_words)))\n    total = sum(frequencies.values())\n    scores = np.asarray(list(frequencies.values())) ** (3 / 4)\n    neg_indices = np.asarray(list(frequencies.keys()))\n    scores = scores / scores.sum()\n    \n    def criterion(preds, targets):\n        random_neg_matrix = np.random.choice(neg_indices, (len(preds), n_negatives), replace=False, p=scores)\n        all_negatives = torch.from_numpy(random_neg_matrix).long().cuda()\n        loss = F.logsigmoid(preds.gather(1, targets.view(-1, 1))) + F.logsigmoid(-preds.gather(1, all_negatives)).sum(dim=1)\n        return -loss.mean()\n    return criterion","metadata":{"execution":{"iopub.status.busy":"2022-12-21T15:17:28.286766Z","iopub.execute_input":"2022-12-21T15:17:28.287736Z","iopub.status.idle":"2022-12-21T15:17:28.297008Z","shell.execute_reply.started":"2022-12-21T15:17:28.287698Z","shell.execute_reply":"2022-12-21T15:17:28.295907Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"loader = DataLoader(skipgram_dataset(tokens), batch_size=64, shuffle=True)\nw2v = SkipGramModel(len(vocabulary_set), 100).cuda()\noptimizer = optim.AdamW(w2v.parameters(), lr=1e-3)\ncriterion = negative_sampling(flat_map(lambda x: x, tokens))\ntrained_skipgram_neg_sample = train(w2v, loader, criterion, optimizer, 10)","metadata":{"execution":{"iopub.status.busy":"2022-12-21T15:17:28.299121Z","iopub.execute_input":"2022-12-21T15:17:28.299663Z","iopub.status.idle":"2022-12-21T15:51:13.036307Z","shell.execute_reply.started":"2022-12-21T15:17:28.299624Z","shell.execute_reply":"2022-12-21T15:51:13.035289Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"100%|██████████| 44443/44443 [03:20<00:00, 222.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 0: mean_loss = 2.8267150283586706\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 44443/44443 [03:19<00:00, 222.33it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: mean_loss = 2.521597244819304\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 44443/44443 [03:19<00:00, 222.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2: mean_loss = 2.461357638896688\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 44443/44443 [03:19<00:00, 222.30it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3: mean_loss = 2.4271082727609152\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 44443/44443 [03:20<00:00, 221.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4: mean_loss = 2.4067710697727356\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 44443/44443 [03:20<00:00, 221.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5: mean_loss = 2.3939527981572524\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 44443/44443 [03:20<00:00, 222.15it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6: mean_loss = 2.3850940919369297\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 44443/44443 [03:19<00:00, 222.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7: mean_loss = 2.378828193595648\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 44443/44443 [03:20<00:00, 221.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8: mean_loss = 2.3744361764296786\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 44443/44443 [03:19<00:00, 222.22it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 9: mean_loss = 2.371357434977695\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"def get_top_k_neares_words(center_vector, model: Word2VecModel, top_k=10):\n    metric = lambda x, y: (x * y).sum()\n    \n    context_embeds = model.classifier.weight.detach().cpu().numpy()\n    norms = np.linalg.norm(context_embeds, axis=1)\n    context_embeds = context_embeds / norms[:, None]\n    \n    word_embed = center_vector / np.linalg.norm(center_vector)\n    \n    idx_and_scores = list(sorted(enumerate(map(lambda candidate: metric(word_embed, candidate), context_embeds)), key=lambda x: -x[1]))\n    return list(map(lambda x: (idx2word[x[0]], x[1]), idx_and_scores[:top_k]))","metadata":{"execution":{"iopub.status.busy":"2022-12-21T15:57:27.212143Z","iopub.execute_input":"2022-12-21T15:57:27.212506Z","iopub.status.idle":"2022-12-21T15:57:27.219346Z","shell.execute_reply.started":"2022-12-21T15:57:27.212474Z","shell.execute_reply":"2022-12-21T15:57:27.218205Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def vector_supplier(model: Word2VecModel, word2idx: dict):\n    space = model.encoder.weight.detach().cpu().numpy()\n    def get_vector_for(name: str) -> np.array:\n        idx = word2idx[name]\n        return space[idx]\n    return get_vector_for","metadata":{"execution":{"iopub.status.busy":"2022-12-21T15:57:28.752116Z","iopub.execute_input":"2022-12-21T15:57:28.752858Z","iopub.status.idle":"2022-12-21T15:57:28.759090Z","shell.execute_reply.started":"2022-12-21T15:57:28.752793Z","shell.execute_reply":"2022-12-21T15:57:28.758021Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"vecs = vector_supplier(trained_skipgram, word2idx)\nget_top_k_neares_words(vecs('daughter'), trained_skipgram)","metadata":{"execution":{"iopub.status.busy":"2022-12-21T15:57:29.623008Z","iopub.execute_input":"2022-12-21T15:57:29.623453Z","iopub.status.idle":"2022-12-21T15:57:29.787168Z","shell.execute_reply.started":"2022-12-21T15:57:29.623421Z","shell.execute_reply":"2022-12-21T15:57:29.786104Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"[('daughter', 0.34646615),\n ('birthday', 0.28236315),\n ('christmas', 0.25895885),\n ('glad', 0.22095025),\n ('give', 0.21278794),\n ('kid', 0.2125443),\n ('old', 0.20815909),\n ('gift', 0.2015148),\n ('year', 0.19457708),\n ('home', 0.18746592)]"},"metadata":{}}]},{"cell_type":"code","source":"vecs = vector_supplier(trained_cbow, word2idx)\nget_top_k_neares_words(vecs('daughter'), trained_cbow)","metadata":{"execution":{"iopub.status.busy":"2022-12-21T15:57:32.658858Z","iopub.execute_input":"2022-12-21T15:57:32.659525Z","iopub.status.idle":"2022-12-21T15:57:32.819663Z","shell.execute_reply.started":"2022-12-21T15:57:32.659490Z","shell.execute_reply":"2022-12-21T15:57:32.818584Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"[('birthday', 0.45944268),\n ('daughter', 0.40525854),\n ('christmas', 0.39061636),\n ('pair', 0.3562856),\n ('walmart', 0.3271615),\n ('sister', 0.3187337),\n ('halloween', 0.2927508),\n ('xmas', 0.2860467),\n ('turkey', 0.28597766),\n ('drink', 0.28179526)]"},"metadata":{}}]},{"cell_type":"code","source":"vecs = vector_supplier(trained_skipgram_neg_sample, word2idx)\nget_top_k_neares_words(vecs('daughter'), trained_skipgram_neg_sample)","metadata":{"execution":{"iopub.status.busy":"2022-12-21T15:57:35.450032Z","iopub.execute_input":"2022-12-21T15:57:35.450410Z","iopub.status.idle":"2022-12-21T15:57:35.609968Z","shell.execute_reply.started":"2022-12-21T15:57:35.450379Z","shell.execute_reply":"2022-12-21T15:57:35.608874Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"[('daughter', 0.172947),\n ('birthday', 0.16577537),\n ('christmas', 0.16504355),\n ('kid', 0.10893779),\n ('have', 0.096102834),\n ('s', 0.081161775),\n ('son', 0.07468467),\n ('be', 0.0742749),\n ('movie', 0.0740296),\n ('get', 0.07395441)]"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}